{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shawn Cicoria - MiniProject 2\n",
    "\n",
    "## Task 1\n",
    "\n",
    "\n",
    "# Introduction\n",
    "For mini-project 2, I've initially selected the following three datasets:\n",
    "\n",
    "1. Social circles from Facebook - https://snap.stanford.edu/data/ego-Facebook.html\n",
    "2. Social network of GitHub developers - https://snap.stanford.edu/data/github-social.html\n",
    "3. Bitcoin OTC web of trust network - https://snap.stanford.edu/data/soc-sign-bitcoin-otc.html\n",
    "\n",
    "\n",
    "## Social circles from Facebook\n",
    "This data set contains both raw and processed data. The raw data to be used is contained in `facebook_combined.txt` which has `88,234` rows of data with each row the connected nodes - essentially each row represents a connected edge.\n",
    "\n",
    "Each node is identified by an integer in the rage of `0-4038`.\n",
    "\n",
    "### Example data\n",
    "An example set of rows shown below. The data set is tagged as undirected.\n",
    "\n",
    "```csv\n",
    "0 1\n",
    "0 2\n",
    "0 3\n",
    "0 4\n",
    "0 5\n",
    "```\n",
    "\n",
    "### Loading data as edges\n",
    "\n",
    "```python\n",
    "edges = import_data('./data/facebook_combined.txt', skip_header=False, sep=' ', cols=2)\n",
    "print(len(edges)) # result is 88234\n",
    "```\n",
    "\n",
    "## Social network of GitHub developers\n",
    "This data set contains both raw and processed data. The raw data to be used is contained in `musae_git_edges.csv` which has `289,003` rows of data with each row the connected nodes - again, the edges.\n",
    "\n",
    "Each node is identified by an integer in the rage of `0-37,699`.\n",
    "\n",
    "### Example data\n",
    "An example set of rows shown below with first row a header. The data set is tagged as undirected.\n",
    "\n",
    "```csv\n",
    "id_1,id_2\n",
    "0,23977\n",
    "1,34526\n",
    "1,2370\n",
    "1,14683\n",
    "```\n",
    "\n",
    "### Loading data as edges\n",
    "\n",
    "```python\n",
    "# importing GitHub graph data\n",
    "edges_github = import_data('./data/musae_git_edges.csv', skip_header=True, sep=',', cols=2)\n",
    "print(len(edges_github)). # 289003\n",
    "```\n",
    "\n",
    "\n",
    "## Bitcoin OTC web of trust network\n",
    "This data is a directed graph with weights. Weights can be positive or negative (signed).\n",
    "\n",
    "Data is contained in `soc-sign-bitcointotc.csv`. The file is headerless, with four values for each row. Each line has one rating, sorted by time, with the following format:\n",
    "\n",
    "```\n",
    "SOURCE, TARGET, RATING, TIME\n",
    "```\n",
    "\n",
    "SOURCE: node id of source, i.e., rater\n",
    "TARGET: node id of target, i.e., ratee\n",
    "RATING: the source's rating for the target, ranging from -10 to +10 in steps of 1\n",
    "TIME: the time of the rating, measured as seconds since Epoch\n",
    "\n",
    "\n",
    "Thus, our edges are the first two columns, with a direction and weight (rating).\n",
    "\n",
    "Each node is identified by an integer in the rage of `0-5880`.\n",
    "\n",
    "### Example of data\n",
    "\n",
    "```csv\n",
    "6,2,4,1289241911.72836\n",
    "6,5,2,1289241941.53378\n",
    "1,15,1,1289243140.39049\n",
    "4,3,7,1289245277.36975\n",
    "13,16,8,1289254254.44746\n",
    "```\n",
    "\n",
    "### Loading data as edges\n",
    "\n",
    "```python\n",
    "# import btc data\n",
    "edges_btc = import_data('./data/soc-sign-bitcoinotc.csv', skip_header=False, sep=',', cols=3)\n",
    "print(len(edges_btc)). # 35592\n",
    "```\n",
    "\n",
    "## Data Import function\n",
    "\n",
    "```python\n",
    "# importing graph data\n",
    "def import_data(filename, skip_header = False, sep = ',', cols = 2):\n",
    "    rv = []\n",
    "    with open(filename, 'rt') as f:\n",
    "        for line in f:\n",
    "            if skip_header:\n",
    "                skip_header = False\n",
    "                continue\n",
    "            rv.append(line.strip().split(sep)[0:cols])\n",
    "            assert len(rv[len(rv) - 1]) == cols\n",
    "\n",
    "    return rv\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "# Data Summary\n",
    "\n",
    " Name | Directed | Nodes | Edges\n",
    "---|---|---|---\n",
    " Social circles: Facebook | No | 4,039 | 88,234\n",
    " GitHub Social Network | No | 37,700 | 289,003\n",
    " Bitcoin OTC trust weighted signed network | Yes | 5,881 | 35,592\n",
    "\n",
    "\n",
    "## Data descriptions\n",
    "\n",
    "\n",
    " Name | Description\n",
    "---|---\n",
    " Bitcoin OTC trust weighted signed network | This is who\\-trusts\\-whom network of people who trade using Bitcoin on a platform called Bitcoin OTC\\. Since Bitcoin users are anonymous, there is a need to maintain a record of users' reputation to prevent transactions with fraudulent and risky users\\. Members of Bitcoin OTC rate other members in a scale of \\-10 \\(total distrust\\) to \\+10 \\(total trust\\) in steps of 1\\. This is the first explicit weighted signed directed network available for research\\. \n",
    " Social circles: Facebook | This dataset consists of 'circles' \\(or 'friends lists'\\) from Facebook\\. Facebook data was collected from survey participants using this Facebook app\\. The dataset includes node features \\(profiles\\), circles, and ego networks\\.\n",
    " GitHub Social Network | A large social network of GitHub developers which was collected from the public API in June 2019\\. Nodes are developers who have starred at least 10 repositories and edges are mutual follower relationships between them\\. The vertex features are extracted based on the location, repositories starred, employer and e\\-mail address\\. The task related to the graph is binary node classification \\- one has to predict whether the GitHub user is a web or a machine learning developer\\. This target feature was derived from the job title of each user\\. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Task 2 - Task 6 Python Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "larget node has 1045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 8 tests in 0.763s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import unittest\n",
    "\n",
    "class connected_helper:\n",
    "    def __init__(self, G: list = None):\n",
    "        if G is not None:\n",
    "            self.G = G\n",
    "\n",
    "        self.max_id = 0\n",
    "\n",
    "    # Task 2\n",
    "    def import_data(self, filename,\n",
    "                    skip_header = False,\n",
    "                    sep = ',',\n",
    "                    cols = 2) -> list:\n",
    "        rv = []\n",
    "        with open(filename, 'rt') as f:\n",
    "            for line in f:\n",
    "                if skip_header:\n",
    "                    skip_header = False\n",
    "                    continue\n",
    "                row = line.strip().split(sep)[0:cols]\n",
    "                self.max_id = max(self.max_id, int(row[0]), int(row[1]))  # needed later.\n",
    "                row[0] = int(row[0])\n",
    "                row[1] = int(row[1])\n",
    "                rv.append(row)\n",
    "                assert len(rv[len(rv) - 1]) == cols\n",
    "\n",
    "        self.G = rv\n",
    "        return rv\n",
    "\n",
    "    # Task 3 implementation\n",
    "    def node_freq(self, directed=False):\n",
    "        '''faster implementation'''\n",
    "        rv = {}\n",
    "        for r in self.G:\n",
    "            if not directed:\n",
    "                if not r[0] in rv:\n",
    "                    rv[r[0]] = 1\n",
    "                else:\n",
    "                    rv[r[0]] += 1\n",
    "                if not r[1] in rv:\n",
    "                    rv[r[1]] = 1\n",
    "                else:\n",
    "                    rv[r[1]] += 1\n",
    "            else:\n",
    "                if not r[1] in rv:\n",
    "                    rv[r[1]] = 1\n",
    "                else:\n",
    "                    rv[r[1]] += 1\n",
    "\n",
    "        #  return rv\n",
    "        return list(rv.items())  # list of tuples\n",
    "\n",
    "    # Task 3 - alternative and crappy way\n",
    "    def node_frequency(self, directed=False):\n",
    "        '''attempt with numpy\n",
    "        this is NOT used....'''\n",
    "        import numpy as np\n",
    "        if not directed:  # undirected\n",
    "            #  this flips the orig and concatenates it again\n",
    "            a_all = np.concatenate((self.G, np.flip(self.G, axis=1)))\n",
    "        else:\n",
    "            a_all = self.G\n",
    "\n",
    "        unique, counts = np.unique(np.array(a_all)[:, 1], return_counts=True)\n",
    "        frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "        return frequencies\n",
    "\n",
    "    # Task 3\n",
    "    def node_top(self, count=100):\n",
    "        return sorted(\n",
    "            self.node_freq(self.G),\n",
    "            key = lambda x: x[1], reverse=True)[0:100]\n",
    "\n",
    "    # Task 4 implementation.\n",
    "    def get_connected_counts(self) -> list:\n",
    "        '''this just has to count each time a node\n",
    "        appears. This doesn't have to report connected\n",
    "        component structure...'''\n",
    "        # visited = [False] * self.max_id\n",
    "        cc = [0] * (self.max_id + 1)\n",
    "\n",
    "        for edge in self.G:  # this is an edge (from,to)\n",
    "            for node in edge:  # each node\n",
    "                cc[int(node)] += 1\n",
    "\n",
    "        self.connected_counts_alt = cc\n",
    "        return cc\n",
    "\n",
    "    # Task 4 implemeentation -- proper one\n",
    "    #  returns an array where offset is the ID and each\n",
    "    # element is the connected nodes as a sublist.\n",
    "    def get_connected_nodes(self, directed: bool = None, graph: list = None) -> list:\n",
    "        if graph is None:\n",
    "            graph = self.G\n",
    "        if directed is None:\n",
    "            directed = False\n",
    "\n",
    "        cc = [None] * (self.max_id + 1)\n",
    "        visited = [False] * (self.max_id + 1)\n",
    "        counts = [0] * (self.max_id + 1)\n",
    "\n",
    "        for edge in graph:  # edge of (from,to)\n",
    "            node_from = edge[0]\n",
    "            node_to = edge[1]\n",
    "\n",
    "            if not visited[int(node_from)]:\n",
    "                cc[int(node_from)] = [node_to]\n",
    "                visited[int(node_from)] = True\n",
    "                #  counts[int(node_from)] = 1\n",
    "            else:\n",
    "                cc[int(node_from)] = cc[int(node_from)] + [node_to]\n",
    "\n",
    "            counts[int(node_from)] += 1\n",
    "\n",
    "            if not directed:\n",
    "                if not visited[int(node_to)]:\n",
    "                    cc[int(node_to)] = [node_from]\n",
    "                    visited[int(node_to)] = True\n",
    "                    #  counts[int(node_to)] = 1\n",
    "                else:\n",
    "                    cc[int(node_to)] = cc[int(node_to)] + [node_from]\n",
    "\n",
    "                counts[int(node_to)] += 1\n",
    "\n",
    "        self.connected_nodes = cc\n",
    "        self.connected_counts = counts\n",
    "        return cc\n",
    "\n",
    "    def get_largest_node_degree(self):\n",
    "        if self.G is None:\n",
    "            raise 'Must iomport data first'\n",
    "\n",
    "        _ = self.get_connected_nodes()\n",
    "        max_index = self.connected_counts.index(max(self.connected_counts))\n",
    "\n",
    "        return max_index, self.connected_nodes[max_index]\n",
    "\n",
    "    #  def dfs_util(self, node, visited):\n",
    "    #     visited[int(node)\n",
    "\n",
    "    # Task 4 alternative method but an adjacency list as dict.\n",
    "    def get_connected_counts_alt(self):\n",
    "        '''alternative implementation'''\n",
    "        from collections import defaultdict\n",
    "        # adj_list = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        # adj_list = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        # this alleviates need to pre-alloc an array of n items\n",
    "        # and discovering the ID's of all the unique nodes.\n",
    "        mysum = defaultdict(int)\n",
    "        for start, end in self.G:\n",
    "            # adj_list[start][end] += 1\n",
    "            mysum[start] += 1\n",
    "            mysum[end] += 1\n",
    "\n",
    "        self.connected_counts_alt2 = mysum\n",
    "        return mysum\n",
    "\n",
    "    # Task 5 parts\n",
    "    def get_reversed_graph(self, graph=None):\n",
    "        if graph is None:\n",
    "            graph = self.G\n",
    "\n",
    "        self.R = [None] * len(graph)\n",
    "        for i, edge in enumerate(graph):  # edge of (from,to)\n",
    "            node_from = edge[0]\n",
    "            node_to = edge[1]\n",
    "            self.R[i] = [node_to, node_from]\n",
    "\n",
    "        return self.R\n",
    "\n",
    "    def get_scc(self, G=None):\n",
    "        # if a graph is already imported it is in the\n",
    "        # [[1,2], [2,3]] format and needs to be connected component instead.\n",
    "        if G is None:\n",
    "            G = self.get_connected_nodes(directed=True, graph=self.G)\n",
    "        else:\n",
    "            G = self.get_connected_nodes(directed=True, graph=G)\n",
    "\n",
    "        # this has to be interative as stack overflow on datasets with more than 500 edges.\n",
    "        n = len(G)\n",
    "        transposed = [[None]] * n\n",
    "        order_w = []\n",
    "        visited = [False] * n\n",
    "        scc = [None] * n\n",
    "\n",
    "        # transpose and first DFS with order by weight\n",
    "        for u in range(n):\n",
    "            if not visited[u]:\n",
    "                visited[u] = True\n",
    "                stack = [u]\n",
    "\n",
    "                while len(stack) > 0:\n",
    "                    u = stack[-1]  # peek at last item.\n",
    "                    done = True\n",
    "                    # tv = G[u]   # odd bug I can't id.\n",
    "                    if G[u] is None:\n",
    "                        break\n",
    "\n",
    "                    for v in G[u]:\n",
    "                        if transposed[v][0] is None:\n",
    "                            transposed[v] = [u]\n",
    "                        else:\n",
    "                            transposed[v].append(u)\n",
    "                        if not visited[v]:\n",
    "                            visited[v] = True\n",
    "                            done = False\n",
    "                            stack.append(v)\n",
    "                            break\n",
    "                    if done:\n",
    "                        stack.pop()\n",
    "                        order_w.append(u)\n",
    "\n",
    "        # second DFS on tranposed to build the scc array\n",
    "        while len(order_w) > 0:\n",
    "            r = order_w.pop()\n",
    "            stack = [r]\n",
    "            if visited[r]:\n",
    "                visited[r] = False\n",
    "                scc[r] = r\n",
    "            while len(stack) > 0:\n",
    "                u = stack[-1]\n",
    "                done = True\n",
    "                if transposed[u][0] is not None:\n",
    "                    for v in transposed[u]:\n",
    "                        if visited[v]:\n",
    "                            done = False\n",
    "                            visited[v] = False\n",
    "                            stack.append(v)\n",
    "                            scc[v] = r\n",
    "                            break\n",
    "                if done:\n",
    "                    stack.pop()\n",
    "\n",
    "        return scc\n",
    "\n",
    "    # Task 6 - this i've taken from my HW5 submission.\n",
    "    def get_adj_matrix(self, data=None, directed=None):\n",
    "        if data is None:\n",
    "            data = self.G\n",
    "        if directed is None:\n",
    "            directed = False\n",
    "\n",
    "        data = np.array(data)\n",
    "        #  get the node list\n",
    "        nodes = np.unique(data)\n",
    "        n = len(nodes)\n",
    "        # create a dict\n",
    "        node_dict = {n: i for i, n in enumerate(nodes)}\n",
    "\n",
    "        # inverted to vector\n",
    "        numdata = np.vectorize(node_dict.get)(data)\n",
    "        am = np.zeros((n, n),)\n",
    "        for j, i in numdata:\n",
    "            am[j, i] = 1\n",
    "            if not directed:\n",
    "                am[i, j] = 1\n",
    "\n",
    "        return am.astype(int)\n",
    "\n",
    "    # Task 6\n",
    "    def get_number_paths(self, adj_matrix, source, target, k):\n",
    "        # give up if K is exhaused (zero or negative.)\n",
    "        if (k == 0 and source == target):\n",
    "            return 1\n",
    "        if (k <= 0):\n",
    "            return 0\n",
    "\n",
    "        n = len(adj_matrix)\n",
    "        steps = 0\n",
    "        # traverse the adj matrix\n",
    "        for i in range(n):\n",
    "            if (adj_matrix[source][i] == 1):  # have a connection.\n",
    "                # deduct step and recursive call; add to current steps.\n",
    "                steps += self.get_number_paths(adj_matrix, i, target, k - 1)\n",
    "\n",
    "        return steps\n",
    "\n",
    "\n",
    "class test_one(unittest.TestCase):\n",
    "    def setUp(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def test_steps(self):\n",
    "        arr = [[0, 1], [1, 0], [1, 2], [2, 0], [2, 3], [2, 4], [3, 4], [4, 5], [5, 6], [6, 4], [7, 6]]\n",
    "        s = connected_helper(G=arr)\n",
    "        s.max_id = 7\n",
    "        adj = s.get_adj_matrix(directed=True)\n",
    "\n",
    "        act = s.get_number_paths(adj, 0, 1, 1)\n",
    "        self.assertEqual(1, act, 'path is 1')\n",
    "\n",
    "        act = s.get_number_paths(adj, 3, 4, 1)\n",
    "        self.assertEqual(1, act, 'path is 1')\n",
    "\n",
    "        act = s.get_number_paths(adj, 2, 4, 2)\n",
    "        self.assertEqual(1, act, 'path is 1')\n",
    "\n",
    "        act = s.get_number_paths(adj, 4, 5, 3)\n",
    "        self.assertEqual(0, act, 'path is 1')\n",
    "\n",
    "    def test_steps_two(self):\n",
    "        arr = [[0, 1], [0, 3], [0, 2], [1, 3], [2, 3]]\n",
    "        s = connected_helper(G=arr)\n",
    "        s.max_id = 3\n",
    "        adj = s.get_adj_matrix(directed=True)\n",
    "        act = s.get_number_paths(adj, 0, 3, 2)\n",
    "        self.assertEqual(2, act, 'path is 1')\n",
    "\n",
    "    def test_adj_matrix(self):\n",
    "        arr = [[0, 1], [1, 0], [1, 2], [2, 0], [2, 3], [2, 4], [3, 4], [4, 5], [5, 6], [6, 4], [7, 6]]\n",
    "        s = connected_helper(G=arr)\n",
    "        s.max_id = 7\n",
    "\n",
    "        act = s.get_adj_matrix(directed=True)\n",
    "        self.assertIsNotNone(act)\n",
    "\n",
    "    def test_dfs_one(self):\n",
    "        # arr = [[1, 2], [2, 3], [2, 5], [3, 4], [4, 6], [5, 1], [6, 3]]\n",
    "        arr = [[0, 1], [1, 0], [1, 2], [2, 0], [2, 3], [2, 4], [3, 4], [4, 5], [5, 6], [6, 4], [7, 6]]\n",
    "        #  cn_exp = [[1], [0, 2], [0, 3, 4], [4], [5], [6], [4], [6]]\n",
    "        s = connected_helper(G=arr)\n",
    "        s.max_id = 7\n",
    "\n",
    "        act = s.get_scc(arr)\n",
    "        exp = [0, 0, 0, 3, 4, 4, 4, 7]\n",
    "        self.assertIsNotNone(act)\n",
    "        self.assertListEqual(act, exp, 'alg done...')\n",
    "\n",
    "    def test_reverse(self):\n",
    "        arr = [['0', '2'], ['0', '3'], ['1', '1']]\n",
    "        exp = [['2', '0'], ['3', '0'], ['1', '1']]\n",
    "        s = connected_helper(G=arr)\n",
    "        s.max_id = 3\n",
    "        act = s.get_reversed_graph()\n",
    "        self.assertListEqual(exp, act, 'reverse to orig ok')\n",
    "\n",
    "    def test_one(self):\n",
    "        arr = [['0', '2'], ['0', '3'], ['1', '1']]\n",
    "        s = connected_helper(G=arr)\n",
    "        s.max_id = 3\n",
    "        cn = s.get_connected_nodes()\n",
    "\n",
    "        self.assertIsNotNone(cn)\n",
    "\n",
    "    def test_with_fb(self):\n",
    "        s_fb = connected_helper()\n",
    "        s_fb.import_data('./data/facebook_combined.txt', skip_header=False, sep=' ', cols=2)\n",
    "        cn = s_fb.get_connected_nodes()\n",
    "        cn_2 = s_fb.get_connected_counts()\n",
    "        self.assertIsNotNone(cn)\n",
    "        self.assertListEqual(cn_2, s_fb.connected_counts_alt, 'two connected counts')\n",
    "\n",
    "    # @unittest.skip('data not present')\n",
    "    def test_larget_node(self):\n",
    "        s_fb = connected_helper()\n",
    "        s_fb.import_data('./data/facebook_combined.txt', skip_header=False, sep=' ', cols=2)\n",
    "        index, con_nodes = s_fb.get_largest_node_degree()\n",
    "\n",
    "        print('larget node has {}'.format(len(con_nodes)))\n",
    "\n",
    "        self.assertIsNotNone(con_nodes)\n",
    "        self.assertEqual(1045, len(con_nodes), 'length of connections')\n",
    "        self.assertEqual(107, index, 'index of larget node')\n",
    "        self.assertEqual(s_fb.connected_counts[107], len(con_nodes))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "    # unittest.main(verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Task 2 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88234\n",
      "289003\n",
      "35592\n"
     ]
    }
   ],
   "source": [
    "s_fb = connected_helper()\n",
    "edges_facebook = s_fb.import_data('./data/facebook_combined.txt', skip_header=False, sep=' ', cols=2)\n",
    "print(len(edges_facebook))  # result is 88234\n",
    "\n",
    "# importing GitHub graph data\n",
    "s_gh = connected_helper()\n",
    "edges_github = s_gh.import_data('./data/musae_git_edges.csv', skip_header=True, sep=',', cols=2)\n",
    "print(len(edges_github))\n",
    "\n",
    "# import btc data\n",
    "s_btc = connected_helper()\n",
    "edges_btc = s_btc.import_data('./data/soc-sign-bitcoinotc.csv', skip_header=False, sep=',', cols=3)\n",
    "print(len(edges_btc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following gives the top 100\n",
    "fb_100 = s_fb.node_top(edges_facebook)\n",
    "gh_100 = s_gh.node_top(edges_github)\n",
    "btc_100 = s_btc.node_top(edges_btc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1888, 251), (2543, 246), (1800, 216), (2611, 197), (1827, 186), (1730, 183), (2607, 183), (1833, 182), (2602, 182), (2604, 182)]\n",
      "[(31890, 7470), (35773, 2401), (36652, 2285), (18163, 1858), (19222, 1499), (36628, 1477), (35008, 1472), (3712, 884), (13638, 858), (30002, 819)]\n",
      "[(35, 535), (2642, 412), (1810, 311), (2028, 279), (905, 264), (1, 226), (4172, 222), (7, 216), (4197, 203), (13, 191)]\n"
     ]
    }
   ],
   "source": [
    "## just show the top 10 of the top 100\n",
    "\n",
    "## output is (ID, count)\n",
    "print(fb_100[0:10])\n",
    "print(gh_100[0:10])\n",
    "print(btc_100[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small dataset result\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['2', '3'], ['1', '1'], ['0'], ['0']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [['0', '2'], ['0', '3'], ['1', '1']]\n",
    "s = connected_helper(G=arr)\n",
    "s.max_id = 3\n",
    "cn = s.get_connected_nodes()\n",
    "print('small dataset result')\n",
    "cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 20, 115, 116, 149, 226, 312, 326, 333, 343]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ID # 2 is example of smaller \"network connected ID\"\n",
    "s_fb.get_connected_nodes()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_fb.get_connected_nodes()[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 continued.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index ID of largest FB: 107 with 1045 total nodes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "index, con_nodes = s_fb.get_largest_node_degree()\n",
    "print('index ID of largest FB: {} with {} total nodes'.format(index, len(con_nodes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 items from rv:\n",
      "\n",
      "[18335 18335 36562 ... 37691 28140 37694]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(None, 10095),\n",
       " (18335, 190),\n",
       " (23433, 80),\n",
       " (27418, 70),\n",
       " (36955, 69),\n",
       " (2433, 61),\n",
       " (35970, 59),\n",
       " (26989, 57),\n",
       " (29665, 43),\n",
       " (33416, 39)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv = s_gh.get_scc()\n",
    "import numpy as np\n",
    "nnn = np.array(rv)\n",
    "\n",
    "\n",
    "print('top 5 items from rv:\\n')\n",
    "print(nnn[nnn!=None])\n",
    "# here are the top ten... \n",
    "import collections\n",
    "collections.Counter(rv).most_common(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "## Using a sample array.  which underneath uses adjacency matrix.\n",
    "\n",
    "arr = [[0, 1], [0, 3], [0, 2], [1, 3], [2, 3]]\n",
    "s = connected_helper(G=arr)\n",
    "s.max_id = 3\n",
    "adj = s.get_adj_matrix(directed=True)\n",
    "act = s.get_number_paths(adj, 0, 3, 2)\n",
    "\n",
    "print(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1]\n",
      " [1 0 0 1]\n",
      " [1 0 0 1]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(s.get_adj_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for facebook it's quite large...\n",
    "adj = s_fb.get_adj_matrix(directed=True)\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4039"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of ID's in FB adjacenc matrix\n",
    "len(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
